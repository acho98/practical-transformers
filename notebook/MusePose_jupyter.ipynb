{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7da6e92-7ffa-495c-94d8-0c55d8d70252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MusePose'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 77 (delta 13), reused 5 (delta 5), pack-reused 58\u001b[K\n",
            "Receiving objects: 100% (77/77), 2.75 MiB | 13.18 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "/content/MusePose\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m396.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "02bde7|\u001b[1;32mOK\u001b[0m  |   168MiB/s|/content/MusePose/pretrained_weights/MusePose/denoising_unet.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "bfa590|\u001b[1;32mOK\u001b[0m  |   218MiB/s|/content/MusePose/pretrained_weights/MusePose/motion_module.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2572c4|\u001b[1;32mOK\u001b[0m  |   145MiB/s|/content/MusePose/pretrained_weights/MusePose/pose_guider.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "db19e1|\u001b[1;32mOK\u001b[0m  |   139MiB/s|/content/MusePose/pretrained_weights/MusePose/reference_unet.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "21fd6c|\u001b[1;32mOK\u001b[0m  |   237MiB/s|/content/MusePose/pretrained_weights/dwpose/dw-ll_ucoco_384.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e51ee3|\u001b[1;32mOK\u001b[0m  |   237MiB/s|/content/MusePose/pretrained_weights/dwpose/yolox_l_8x8_300e_coco.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "d0e85c|\u001b[1;32mOK\u001b[0m  |   255MiB/s|/content/MusePose/pretrained_weights/image_encoder/pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "a3bb73|\u001b[1;32mOK\u001b[0m  |    98KiB/s|/content/MusePose/pretrained_weights/image_encoder/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "22f412|\u001b[1;32mOK\u001b[0m  |   166MiB/s|/content/MusePose/pretrained_weights/sd-image-variations-diffusers/unet/diffusion_pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6339cf|\u001b[1;32mOK\u001b[0m  |   121KiB/s|/content/MusePose/pretrained_weights/sd-image-variations-diffusers/unet/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "7064a1|\u001b[1;32mOK\u001b[0m  |   224MiB/s|/content/MusePose/pretrained_weights/sd-vae-ft-mse/diffusion_pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "71eca5|\u001b[1;32mOK\u001b[0m  |    76KiB/s|/content/MusePose/pretrained_weights/sd-vae-ft-mse/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/MusePose\n",
        "%cd /content/MusePose\n",
        "\n",
        "!pip install -q torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 torchtext==0.16.0 torchdata==0.7.0 --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab/mmcv-2.0.1-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q moviepy av diffusers==0.24.0 einops omegaconf transformers==4.33.1 accelerate==0.29.3 mmdet mmpose\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/MusePose/denoising_unet.pth -d /content/MusePose/pretrained_weights/MusePose -o denoising_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/MusePose/motion_module.pth -d /content/MusePose/pretrained_weights/MusePose -o motion_module.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/MusePose/pose_guider.pth -d /content/MusePose/pretrained_weights/MusePose -o pose_guider.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/MusePose/reference_unet.pth -d /content/MusePose/pretrained_weights/MusePose -o reference_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/dwpose/dw-ll_ucoco_384.pth -d /content/MusePose/pretrained_weights/dwpose -o dw-ll_ucoco_384.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/dwpose/yolox_l_8x8_300e_coco.pth -d /content/MusePose/pretrained_weights/dwpose -o yolox_l_8x8_300e_coco.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/image_encoder/pytorch_model.bin -d /content/MusePose/pretrained_weights/image_encoder -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/raw/main/image_encoder/config.json -d /content/MusePose/pretrained_weights/image_encoder -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/sd-image-variations-diffusers/diffusion_pytorch_model.bin -d /content/MusePose/pretrained_weights/sd-image-variations-diffusers/unet -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/raw/main/sd-image-variations-diffusers/config.json -d /content/MusePose/pretrained_weights/sd-image-variations-diffusers/unet -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/resolve/main/sd-vae-ft-mse/diffusion_pytorch_model.bin -d /content/MusePose/pretrained_weights/sd-vae-ft-mse -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/MusePose/raw/main/sd-vae-ft-mse/config.json -d /content/MusePose/pretrained_weights/sd-vae-ft-mse -o config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G_EBLYlT1U78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34d3172-497d-4379-f19b-eb69e08c6548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "height: 1920.0\n",
            "width: 1080.0\n",
            "fps: 24.0\n",
            "2024-06-07 04:05:21.758018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-07 04:05:21.758068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-07 04:05:21.873222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-07 04:05:24.224423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loads checkpoint by local backend from path: ./pretrained_weights/dwpose/yolox_l_8x8_300e_coco.pth\n",
            "Loads checkpoint by local backend from path: ./pretrained_weights/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "pose_list len: 288\n",
            "Moviepy - Building video ./assets/poses/align_demo/img_ref_video_dance.mp4.\n",
            "Moviepy - Writing video ./assets/poses/align_demo/img_ref_video_dance.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./assets/poses/align_demo/img_ref_video_dance.mp4\n",
            "Moviepy - Building video ./assets/poses/align/img_ref_video_dance.mp4.\n",
            "Moviepy - Writing video ./assets/poses/align/img_ref_video_dance.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./assets/poses/align/img_ref_video_dance.mp4\n",
            "pose align done\n"
          ]
        }
      ],
      "source": [
        "!python pose_align.py --imgfn_refer ./assets/images/ref.png --vidfn ./assets/videos/dance.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XHCtzhY11U79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3712c474-db46-4486-eb2b-e6fa37d90165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-07 04:07:13.193397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-07 04:07:13.193449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-07 04:07:13.194987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-07 04:07:15.095480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Width: 448\n",
            "Height: 448\n",
            "Length: 300\n",
            "Slice: 48\n",
            "Overlap: 4\n",
            "Classifier free guidance: 3.5\n",
            "DDIM sampling steps : 20\n",
            "skip 1\n",
            "Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: \n",
            " ['conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "handle=== ./assets/images/ref.png ./assets/poses/align/img_ref_video_dance.mp4\n",
            "pose video has 288 frames, with 24 fps\n",
            "processing length: 144\n",
            "fps 12\n",
            "/content/MusePose/musepose/pipelines/pipeline_pose2vid_long.py:406: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  num_channels_latents = self.denoising_unet.in_channels\n",
            "100% 20/20 [10:09<00:00, 30.47s/it]\n",
            "100% 180/180 [00:25<00:00,  7.17it/s]\n"
          ]
        }
      ],
      "source": [
        "!python test_stage_2.py --config ./configs/test_stage_2.yaml -W 448 -H 448"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pose_align.py --imgfn_refer ./assets/images/ref.png --vidfn ./assets/videos/dance.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWVcjr-75csC",
        "outputId": "e8a470a4-1173-48e0-ec8b-b11fffddd8c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "height: 1280.0\n",
            "width: 720.0\n",
            "fps: 30.0\n",
            "2024-06-07 05:28:14.614306: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-07 05:28:14.614362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-07 05:28:14.615788: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-07 05:28:15.890876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loads checkpoint by local backend from path: ./pretrained_weights/dwpose/yolox_l_8x8_300e_coco.pth\n",
            "Loads checkpoint by local backend from path: ./pretrained_weights/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "pose_list len: 300\n",
            "Moviepy - Building video ./assets/poses/align_demo/img_ref_video_dance.mp4.\n",
            "Moviepy - Writing video ./assets/poses/align_demo/img_ref_video_dance.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./assets/poses/align_demo/img_ref_video_dance.mp4\n",
            "Moviepy - Building video ./assets/poses/align/img_ref_video_dance.mp4.\n",
            "Moviepy - Writing video ./assets/poses/align/img_ref_video_dance.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./assets/poses/align/img_ref_video_dance.mp4\n",
            "pose align done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_stage_2.py --config ./configs/test_stage_2.yaml -W 448 -H 448"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEKR-af5cyg",
        "outputId": "0d1ac2f7-8436-4cf4-c11d-9a867012e35e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-07 05:30:47.895921: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-07 05:30:47.895978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-07 05:30:47.898040: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-07 05:30:49.589520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Width: 448\n",
            "Height: 448\n",
            "Length: 300\n",
            "Slice: 48\n",
            "Overlap: 4\n",
            "Classifier free guidance: 3.5\n",
            "DDIM sampling steps : 20\n",
            "skip 1\n",
            "Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: \n",
            " ['conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "handle=== ./assets/images/ref.png ./assets/poses/align/img_ref_video_dance.mp4\n",
            "pose video has 300 frames, with 30 fps\n",
            "processing length: 150\n",
            "fps 15\n",
            "/content/MusePose/musepose/pipelines/pipeline_pose2vid_long.py:406: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  num_channels_latents = self.denoising_unet.in_channels\n",
            "100% 20/20 [10:09<00:00, 30.45s/it]\n",
            "100% 180/180 [00:25<00:00,  7.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxsPIBk2-mTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}